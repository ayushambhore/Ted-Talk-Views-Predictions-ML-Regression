{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushambhore/Ted-Talk-Views-Predictions-ML-Regression/blob/master/Ted_Talk_Views_Predictions_ML_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name : Ayush Ambhore**"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/ayushambhore/Ted-Talk-Views-Predictions-ML-Regression"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main objective is to build a predictive model, which could help in predicting the views of the videos uploaded on the TED website."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import calendar\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "url = 'https://raw.githubusercontent.com/ayushambhore/Ted-Talk-Views-Predictions-ML-Regression/master/data_ted_talks.csv'\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(f' Row count = {df.shape[0]}\\n Column count = {df.shape[1]}')"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(df[df.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum().sum())"
      ],
      "metadata": {
        "id": "ZfredsJG5k0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(), cbar=False);"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data set is about Ted talk videos. The data set have 4005 rows and 19 columns. The data have no duplicate rows. The data have 1685 missing values."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. talk_id : Unique ID\n",
        "2. title : Title of the video\n",
        "3. speaker_1: Main speaker in the video\n",
        "4. all_speakers : name of all speakers in the video\n",
        "5. occupations: occupations of the main speaker\n",
        "6. about_speakers: description about the speakers\n",
        "7. views : total views on the video\n",
        "8. recorder_date: the date of the recording of the video\n",
        "9. published_date : date of publish of the video\n",
        "10. event: event name\n",
        "11. native_lang : the language in which the video was recorded\n",
        "12. available_lang : available languages for the video\n",
        "13. comments : total comments on the video\n",
        "14. duration : duration of the video\n",
        "15. topics : topics related to the video\n",
        "16. related_talks : ID and the name of the related TED video\n",
        "17. url : url link of the video\n",
        "18. description : description of the video\n",
        "19. transcript: transcript of the video"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Null values**"
      ],
      "metadata": {
        "id": "MoOI7e4P6lYs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we saw earlier all_speakers column have 4 missing values, occupations column have 522 missing values, about_speakers have 503 missing values, recorded_date have 1 missing value and comments have 655 missing values."
      ],
      "metadata": {
        "id": "1Efz6yaS6qX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. all_speakers have 4 missing values , missing value here suggests that only one speaker was there.\n",
        "So we will drop the NaN values in all_speakers column."
      ],
      "metadata": {
        "id": "JHyUQ0E36uBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset= ['all_speakers'])"
      ],
      "metadata": {
        "id": "6bLjIeul_wke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. The columns- occupations and about speakers have 522 and 503 missing values respectively.\n",
        "so we will replace these NaN values with 'NA'."
      ],
      "metadata": {
        "id": "mQgxLqMo60mH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['occupations'].fillna(str({0:'NA'}),inplace=True,axis=0)"
      ],
      "metadata": {
        "id": "_8TPB3_z65Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['about_speakers'].fillna(str({0:'NA'}),inplace=True,axis=0)"
      ],
      "metadata": {
        "id": "ZPCeBhNWCxnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. recorded_date have only 1 missing value so we will drop that row."
      ],
      "metadata": {
        "id": "0fPfdDwLC8Ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset= ['recorded_date'])"
      ],
      "metadata": {
        "id": "YAV-vo3yDL6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. The comment section has the most number of missing values , which can mean 2 things either no have commented on that video or the comments are disables , keeping in mind both the cases we will replace these Nan values with 0."
      ],
      "metadata": {
        "id": "xzONJvEsDS7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['comments'].fillna(0, inplace = True)"
      ],
      "metadata": {
        "id": "vLZ2Us_cD2Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking our final data"
      ],
      "metadata": {
        "id": "Wcgfl3YIETHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "BCDPtoS7EXvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(), cbar=False);"
      ],
      "metadata": {
        "id": "d5KWDRpgEf9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our data have no missing values , that means our data is clean and we are ready for the next steps."
      ],
      "metadata": {
        "id": "DknyNSdEEkim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Null values**"
      ],
      "metadata": {
        "id": "6b51zKv4tt8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we saw earlier all_speakers column have 4 missing values, occupations column have 522 missing values, about_speakers have 503 missing values, recorded_date have 1 missing value and comments have 655 missing values."
      ],
      "metadata": {
        "id": "OKuiUyD9tt8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. all_speakers have 4 missing values , missing value here suggests that only one speaker was there.\n",
        "So we will drop the NaN values in all_speakers column."
      ],
      "metadata": {
        "id": "OQ1kZnyrtt8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset= ['all_speakers'])"
      ],
      "metadata": {
        "id": "R9izfrWytt8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. The columns- occupations and about speakers have 522 and 503 missing values respectively.\n",
        "so we will replace these NaN values with 'NA'."
      ],
      "metadata": {
        "id": "lpomfdcGtt8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['occupations'].fillna(str({0:'NA'}),inplace=True,axis=0)"
      ],
      "metadata": {
        "id": "ogzzLhWUtt8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['about_speakers'].fillna(str({0:'NA'}),inplace=True,axis=0)"
      ],
      "metadata": {
        "id": "JWNDHJQctt8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. recorded_date have only 1 missing value so we will drop that row."
      ],
      "metadata": {
        "id": "CPt0ixemtt8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset= ['recorded_date'])"
      ],
      "metadata": {
        "id": "GhtA2li4tt8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. The comment section has the most number of missing values , which can mean 2 things either no have commented on that video or the comments are disables , keeping in mind both the cases we will replace these Nan values with 0."
      ],
      "metadata": {
        "id": "zhd1ytgwtt8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['comments'].fillna(0, inplace = True)"
      ],
      "metadata": {
        "id": "537xtMTUtt8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking our final data"
      ],
      "metadata": {
        "id": "8R38TOKvtt8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "pbocQ4TWtt8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(), cbar=False);"
      ],
      "metadata": {
        "id": "OtZS6F03tt8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our data have no missing values , that means our data is clean and we are ready for the next steps."
      ],
      "metadata": {
        "id": "KzPn0Hq0tt8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1: **Barplot** on top 10 most popular TED talk videos"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top10_most_views = df.sort_values(['views'],ascending=False).head(10)"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data= top10_most_views, x='views',y= 'title')\n",
        "\n",
        "plt.xlabel('Views in Billions')\n",
        "plt.title('Count',fontsize = 12);"
      ],
      "metadata": {
        "id": "sCxoSCoXIO_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar charts show the frequency counts of values for the different levels of a categorical or nominal variable."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the most popular video is the 'Do schools kill creativity?'"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The new content creators should note that people are more interested in these 10 topics so they should make more content on this."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2:  **Barplot** on top 10 most popular speakers on TED talk videos"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_speakers_wrt_views = df.groupby('speaker_1')\n",
        "top_speakers_wrt_views= top_speakers_wrt_views.sum()\n",
        "top_speakers_wrt_views = top_speakers_wrt_views.sort_values(['views'],ascending= False).reset_index().head(10)\n"
      ],
      "metadata": {
        "id": "pnyGbbMULnKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data= top_speakers_wrt_views, x='views',y= 'speaker_1')\n",
        "\n",
        "plt.xlabel('Views in Billions')\n",
        "plt.title('Count',fontsize = 12);"
      ],
      "metadata": {
        "id": "n0Q2KreqM1c7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar plot provides a clear visual representation of the top 10 speakers."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see the top most popular speaker is Alex Gendler."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TED organization should approach these speakers more as they are bringing the most views to their videos."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3 : **Countplot** on top 10 speakers with highest number of talks they delivered."
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speaker_vs_frequency = df['speaker_1'].value_counts().head(10)\n",
        "speaker_vs_frequency"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(y='speaker_1',\n",
        "              data=df,\n",
        "              order=speaker_vs_frequency.index,\n",
        "              palette=\"rocket\")\n",
        "sns.color_palette(\"rocket\")\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Speakers');"
      ],
      "metadata": {
        "id": "MXofQyG4PnNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Countplot show the counts of observations in each categorical bin using bars. A count plot can be thought of as a histogram across a categorical, instead of quantitative, variable."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alex Gendler has delivered the highest number of talks."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4: **Barplot** on top 10 speakers with respect to average views"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speakers_vs_avgviews= df.groupby('speaker_1',as_index=False)['views']\n",
        "speakers_vs_avgviews= speakers_vs_avgviews.mean()\n",
        "speakers_vs_avgviews = speakers_vs_avgviews.sort_values(['views'],ascending = False).head(10)\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_param1 =speakers_vs_avgviews['speaker_1']\n",
        "x_param1 =speakers_vs_avgviews['views']"
      ],
      "metadata": {
        "id": "BJwdPBZ-WCqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = sns.barplot(x = x_param1,\n",
        "                    y = y_param1 ,\n",
        "                    linewidth=2,\n",
        "                    color='#ff5252')\n",
        "\n",
        "graph.set_title(\"Top 10 speakers with respect to average views\");"
      ],
      "metadata": {
        "id": "_xxMhrjNWNXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bar plots in this study visually describe the mean of a views with respect to the speaker."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amy cuddy has the highest average views among all the speakers."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TED organization should approach these speakers more as they have the highest average views."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5: **Barplot** on Top 10 speakers with highest number of comments"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_speakers_wrt_comments = df.groupby('speaker_1')\n",
        "top_speakers_wrt_comments= top_speakers_wrt_comments.sum()\n",
        "top_speakers_wrt_comments = top_speakers_wrt_comments.sort_values(['comments'],ascending= False).reset_index().head(10)\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data= top_speakers_wrt_comments, x='comments',y= 'speaker_1')\n",
        "\n",
        "plt.xlabel('comments')\n",
        "plt.title('Count',fontsize = 12);"
      ],
      "metadata": {
        "id": "KvwtS4kMYqud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar plot provides a clear visual representation of the top 10 speakers with respect to comments."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Richard Dawkins have the most number of comments on his videos."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6: **Barplot** on popular events"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_talk_event=df.groupby(['event'],as_index=False).agg({'views':'sum','talk_id':'count'}).sort_values('views',ascending=False).reset_index()[:8]\n",
        "top_talk_event['talk_id']=top_talk_event['views']/top_talk_event['talk_id']"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(data= top_talk_event, x='views',y= 'event')\n",
        "\n",
        "plt.xlabel('Views in Billions')\n",
        "plt.title('Count',fontsize = 12)"
      ],
      "metadata": {
        "id": "bOCxrFvzsN9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar charts make sense for categorical or nominal data, since they are measured on a scale with specific possible values. With categorical data, the sample is often divided into groups, and the responses have a defined order."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can clearly see the most popular event is TED-ed"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7: **Density plot** on available languages"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['number_of_lang'] = df['available_lang'].apply(lambda x: len(x))"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df['number_of_lang'])"
      ],
      "metadata": {
        "id": "q7XIAgQvwu8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Density Plot is the continuous and smoothed version of the Histogram estimated from the data. It is estimated through Kernel Density Estimation. In this method Kernel (continuous curve) is drawn at every individual data point and then all these curves are added together to make a single smoothened density estimation."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can conclude from the chart that more number of videos have number languages between 100 to 250."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8: **Density plot** on number of topics"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['topics'] = df.apply(lambda x: eval(x['topics']), axis=1)\n",
        "df['num_of_topics'] = df.apply(lambda x: len(x['topics']), axis=1)"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.distplot(df['num_of_topics'])"
      ],
      "metadata": {
        "id": "IkZc6wObxPoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Density Plot is the continuous and smoothed version of the Histogram estimated from the data. It is estimated through Kernel Density Estimation. In this method Kernel (continuous curve) is drawn at every individual data point and then all these curves are added together to make a single smoothened density estimation."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see that more number of videos have around 2 to 10 topics."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9: Most frequent words used in the title with **word cloud**"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud,ImageColorGenerator\n",
        "\n",
        "text = \" \".join(topic for topic in df.title.astype(str))\n",
        "\n",
        "\n",
        "wordcloud = WordCloud( width=600, height=350).generate(text)\n",
        "\n",
        "\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.margins(x=0, y=0);"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A visualisation method that displays how frequently words appear in a given body of text, by making the size of each word proportional to its frequency. All the words are then arranged in a cluster or cloud of words."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the that world and life are the most occuring words in the titles."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10: Popular Topic tags with **word cloud**"
      ],
      "metadata": {
        "id": "ot8hKKhw6Fag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \".join(topic for topic in df.topics.astype(str))\n",
        "\n",
        "wordcloud = WordCloud(width=600, height=350).generate(text)\n",
        "\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.margins(x=0, y=0);"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A visualisation method that displays how frequently words appear in a given body of text, by making the size of each word proportional to its frequency. All the words are then arranged in a cluster or cloud of words."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that technology,science and global issues and TED ed are the most occuring words in the topics."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11: **Barplot** on top 10 most frequent speakers occupation."
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_speaker_occ =df['occupations'].value_counts()[1:].head(10).reset_index()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x = top_10_speaker_occ['occupations'],\n",
        "            y = top_10_speaker_occ['index'])\n",
        "\n",
        "\n",
        "plt.ylabel('Occupation',fontsize = 15)\n",
        "plt.title('Count',fontsize = 18);"
      ],
      "metadata": {
        "id": "Egnj-qYp7VBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar charts make sense for categorical or nominal data, since they are measured on a scale with specific possible values. With categorical data, the sample is often divided into groups, and the responses have a defined order."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Writer is the most popular occupation of the speakers."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.set(font_scale=1)\n",
        "heatmap = sns.heatmap(df.corr(), cmap=\"YlGnBu\", annot=True)\n",
        "\n",
        "heatmap.set_title('Correlation Heatmap',\n",
        "                  fontdict={'fontsize':25},\n",
        "                  pad=12);"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A correlation matrix is a table showing correlation coefficients between variables. Each cell in the table shows the correlation between two variables. A correlation matrix is used to summarize data, as an input into a more advanced analysis, and as a diagnostic for advanced analyses. The range of correlation is [-1,1].\n",
        "\n",
        "Thus to know the correlation between all the variables along with the correlation coeficients, i used correlation heatmap."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data manipulation"
      ],
      "metadata": {
        "id": "Xo0eItIHcfQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets look at the columns of our data set"
      ],
      "metadata": {
        "id": "41iGk5gZYfM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "9JWvXuIwJjRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets drop the unecessary columns which will not have any effect on our model building."
      ],
      "metadata": {
        "id": "_b6tetN2Ywy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop( columns = ['talk_id', 'title',\n",
        "                    'about_speakers','event', 'url',\n",
        "                    'description','transcript','native_lang',\n",
        "                    'related_talks', 'available_lang', 'topics',\n",
        "                    'all_speakers', 'occupations'],\n",
        "          inplace = True)"
      ],
      "metadata": {
        "id": "Pd3d7nxiKV7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "PjiE_Qe7KwEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before going further , we should change the format of recorded_date and published_date to datetime format."
      ],
      "metadata": {
        "id": "aDVaDRluZT9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['recorded_date'] = pd.to_datetime(df['recorded_date'], format = '%Y-%m-%d')\n",
        "df['published_date'] = pd.to_datetime(df['published_date'], format = '%Y-%m-%d')"
      ],
      "metadata": {
        "id": "I0usd8DIK98r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a new column video_age_day as it will be required for further data processing."
      ],
      "metadata": {
        "id": "uqz9Bb1QaInj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['video_age_day'] = df['published_date'].max() + timedelta(days=1)-(pd.DatetimeIndex(df['published_date']))\n",
        "df['video_age_day'] = df['video_age_day'].dt.days"
      ],
      "metadata": {
        "id": "fG9zIYzxPHdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating one more column for the average daily views. As this will be key feature in predicting the views of the video."
      ],
      "metadata": {
        "id": "7Y0uJpe2afrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['avg_daily_views'] = df['views'] / df['video_age_day']"
      ],
      "metadata": {
        "id": "c2-5oL6YR8XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining the average views of the speaker of their videos and mapping it to new column."
      ],
      "metadata": {
        "id": "qR86aLiqbeOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speaker_temp=df.groupby('speaker_1').agg({'views' : 'mean'}).sort_values(['views'],ascending=False).to_dict().values()\n",
        "speaker_temp=  list(speaker_temp)[0]\n",
        "df['speaker_1_avg_views']=df['speaker_1'].map(speaker_temp)"
      ],
      "metadata": {
        "id": "dr_2hOMDSacq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets further drop these columns as they are not much relevant for our model."
      ],
      "metadata": {
        "id": "if6jMV6vb2Af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df= df.drop(columns= ['recorded_date', 'published_date', 'speaker_1','number_of_lang' ,'num_of_topics','video_age_day'])"
      ],
      "metadata": {
        "id": "bEoD3H3uOHFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "SnEMcw1AQgo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "TFRC_5y1cnQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "outliers_count = ((df < Q1 - 1.5 * IQR) | (df > Q3 + 1.5 * IQR)).sum(axis=0)\n",
        "\n",
        "outliers_count\n"
      ],
      "metadata": {
        "id": "pdCQAwqhM6tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that very less collinearity is present so we should treat these ."
      ],
      "metadata": {
        "id": "NDVNZg0kc7zU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lower_threshold = Q1 - 1.5 * IQR\n",
        "upper_threshold = Q3 + 1.5 * IQR\n",
        "\n",
        "df = df.mask(df < lower_threshold, Q1, axis=1)\n",
        "df = df.mask(df > upper_threshold, Q3, axis=1)"
      ],
      "metadata": {
        "id": "XKYya8ZWVDD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "outliers_count = ((df < Q1 - 1.5 * IQR) | (df > Q3 + 1.5 * IQR)).sum(axis=0)\n",
        "\n",
        "outliers_count"
      ],
      "metadata": {
        "id": "0rR7TSz4VStc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Assigning Target variable and feature varibales."
      ],
      "metadata": {
        "id": "r_IPk_l_dmks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['views'] #dependent variable"
      ],
      "metadata": {
        "id": "gUPKMdv3R4VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns='views') #independent variables"
      ],
      "metadata": {
        "id": "koD1MJ1HSDKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "id": "UJhzUzyLTSVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Checking VIF"
      ],
      "metadata": {
        "id": "REOERUt2d7cq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Variance Inflation Factor (VIF)\n",
        "Variance inflation factor measures how much the behavior (variance) of an independent variable is influenced, or inflated, by its interaction/correlation with the other independent variables. Variance inflation factors allow a quick measure of how much a variable is contributing to the standard error in the regression."
      ],
      "metadata": {
        "id": "TXZLjBeaeJ_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "selected_features = ['comments', 'duration', 'avg_daily_views', 'speaker_1_avg_views']\n",
        "\n",
        "df_selected = df[selected_features]\n",
        "\n",
        "vif = pd.DataFrame()\n",
        "vif[\"Feature\"] = df_selected.columns\n",
        "vif[\"VIF\"] = [variance_inflation_factor(df_selected.values, i) for i in range(df_selected.shape[1])]\n",
        "\n",
        "\n",
        "print(vif)\n"
      ],
      "metadata": {
        "id": "x0QPIT8XTWR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are good to go as all the VIF is under 10."
      ],
      "metadata": {
        "id": "AltKzz2qeMa6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Checking multicollinearity"
      ],
      "metadata": {
        "id": "n8AWESTieWwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.set(font_scale=1)\n",
        "heatmap = sns.heatmap(X.corr(), cmap=\"YlGnBu\", annot=True)\n",
        "\n",
        "heatmap.set_title('Correlation Heatmap',\n",
        "                  fontdict={'fontsize':25},\n",
        "                  pad=12);"
      ],
      "metadata": {
        "id": "ERm9WhAtT6sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-test split"
      ],
      "metadata": {
        "id": "ru4Wztqqhc1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "reg = LinearRegression().fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "pt88_iDuiA9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = reg.predict(X_test)"
      ],
      "metadata": {
        "id": "YZKWLC1yiM6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "MSE  = mean_squared_error(y_test, y_pred)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)"
      ],
      "metadata": {
        "id": "dAhrqT4xiPbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(y_test, y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "sAhCr9jCitb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Predicted vs Actual Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Aun3U24ikdOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_cross = LinearRegression()\n",
        "parameters = {'positive': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "reg_cross_x = GridSearchCV(reg_cross, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "reg_cross_x.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "XZlAGOwElwst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit positive value is found out to be :\" ,reg_cross_x.best_params_)\n",
        "print(\"\\nUsing \",reg_cross_x.best_params_, \" the negative mean squared error is: \", reg_cross_x.best_score_)"
      ],
      "metadata": {
        "id": "cNe0M-eSnloz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_reg = reg_cross_x.predict(X_test)"
      ],
      "metadata": {
        "id": "6wgfI6B8o2iB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(y_test, y_pred_reg)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Predicted vs Actual Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wyHdtoRxpClJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used Gridsearch as Grid search works by trying every possible combination of parameters you want to try in your model."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No improvement."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "lasso  = Lasso(alpha=0.1 , max_iter= 3000)\n",
        "\n",
        "lasso.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "-lnNxqSOzB6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lasso = lasso.predict(X_test)"
      ],
      "metadata": {
        "id": "iQ6hulcOzKJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(y_test, y_pred_lasso)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred_lasso)\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(y_test, y_pred_lasso))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "qXIHPw6gzXRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(y_test, y_pred_lasso)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Predicted vs Actual Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-dRDii5az1B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100,1000]}\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=5)\n",
        "lasso_regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"\\nUsing \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)"
      ],
      "metadata": {
        "id": "W8RbpAGv0LQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lasso_x = lasso_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "WqoFZ80i0RFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(y_test, y_pred_lasso_x)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred_lasso_x)\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(y_test, y_pred_lasso_x))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "fKuPKii50h9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(y_test, y_pred_lasso_x)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Predicted vs Actual Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LNDi59Py0Zyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used Gridsearch as Grid search works by trying every possible combination of parameters you want to try in your model."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No improvement"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge  = Ridge(alpha=0.1)"
      ],
      "metadata": {
        "id": "qXU9fCBq1eq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "Fp24kO7H21Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "wvFD2d1-23jM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_r = ridge.predict(X_test)"
      ],
      "metadata": {
        "id": "Pn9APdBz258j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(y_test, y_pred_r)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred_r)\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(y_test, y_pred_r))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "8Ke8TCW928Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(y_test, y_pred_r)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Predicted vs Actual Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ifOtovSn3TP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ridge = Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100,6000,7000,8000]}\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_regressor.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
        "print(\"\\nUsing \",ridge_regressor.best_params_, \" the negative mean squared error is: \", ridge_regressor.best_score_)"
      ],
      "metadata": {
        "id": "wd5FCCeQ3z71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_ridge = ridge_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "a1KOZy2J32-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(y_test, y_pred_ridge)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred_ridge)\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(y_test, y_pred_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "yML4knjw35ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(y_test, y_pred_ridge)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Predicted vs Actual Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jKB2miF04XSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used Gridsearch as Grid search works by trying every possible combination of parameters you want to try in your model."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 4"
      ],
      "metadata": {
        "id": "EBt700Sz5osv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "#a * L1 + b * L2\n",
        "#alpha = a + b and l1_ratio = a / (a + b)\n",
        "elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.5)"
      ],
      "metadata": {
        "id": "DIx6tkD85os6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elasticnet.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "3WAP3a2l6iD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elasticnet.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "luSgwe8C6k_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_en = elasticnet.predict(X_test)"
      ],
      "metadata": {
        "id": "l0ojdb3i62Ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(y_test, y_pred_en)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred_en)\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(y_test, y_pred_en))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "98ykIyNq64c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(y_test, y_pred_en)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Predicted vs Actual Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qPHr1SS07Z2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "XgZgk76X5os6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "97vYaiVN5os6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elastic = ElasticNet()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20],'l1_ratio':[0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]}\n",
        "elastic_regressor = GridSearchCV(elastic, parameters, scoring='neg_mean_squared_error',cv=5)\n",
        "elastic_regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "GK_1S2tZ5os6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_elastic = elastic_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "EtGC_TFK9bIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,elastic_regressor.best_params_)\n",
        "print(\"\\nUsing \",elastic_regressor.best_params_, \" the negative mean squared error is: \", elastic_regressor.best_score_)"
      ],
      "metadata": {
        "id": "yk-yJQtB9lR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSE  = mean_squared_error(y_test, y_pred_elastic)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred_elastic)\n",
        "print(\"R2 :\" ,r2)\n",
        "print(\"Adjusted R2 : \",1-(1-r2_score(y_test, y_pred_elastic))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "vhMhVKRz-QpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(y_test, y_pred_elastic)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Predicted vs Actual Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZLMW1YWl-gtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "c-fdlzBd5os6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used Gridsearch as Grid search works by trying every possible combination of parameters you want to try in your model."
      ],
      "metadata": {
        "id": "l6wHUM0a5os6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "HURrlAg75os6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "EP78MJnv5os7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a positive business impact we should choose R2 as it produced the best results in each of the regression models. And there is no overfitting as shown by adjusted R2."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}